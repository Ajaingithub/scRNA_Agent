{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55bd0215",
   "metadata": {},
   "source": [
    "# GEO Curator\n",
    "\n",
    "Making an agent that could find the single cell RNA dataset and find the h5ad, h5Seurat, csv files and downloaded if approved by the user\n",
    "\n",
    "Agent loop through:\n",
    "1. Uses Qwen locally\n",
    "2. Lets the model decide to call a tool\n",
    "3. Executes geo_search\n",
    "4. Feeds results back\n",
    "5. Optionally downloads a dataset\n",
    "\n",
    "User question → LLM thinks → decides: \"I need GEO\" → LLM outputs TOOL_CALL(JSON) → Python executes geo_search() → Tool result injected back into LLM → LLM continues reasoning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ceef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a tool\n",
    "import json\n",
    "from Bio import Entrez\n",
    "\n",
    "Entrez.email = \"abhinavjj@gmail.com\"\n",
    "\n",
    "def geo_search(query: str, retmax: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Search GEO DataSets (GDS) using a query string.\n",
    "    Returns a JSON string of GEO IDs.\n",
    "    \"\"\"\n",
    "    handle = Entrez.esearch(\n",
    "        db=\"gds\",\n",
    "        term=query,\n",
    "        retmax=retmax\n",
    "    )\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "\n",
    "    return json.dumps(record[\"IdList\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8fe47",
   "metadata": {},
   "source": [
    "Since LLM is hard constraints we tell Qwen: If you want to call a tool, output EXACTLY this JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76399099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_call': {'name': 'geo_search', 'arguments': {'query': 'string'}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"tool_call\": {\n",
    "    \"name\": \"geo_search\",\n",
    "    \"arguments\": {\n",
    "      \"query\": \"string\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "# Other wise Normal text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4866c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Add a resolver tool (this fixes everything)\n",
    "import json\n",
    "from Bio import Entrez\n",
    "\n",
    "def geo_summary(uid: str) -> str:\n",
    "    \"\"\"\n",
    "    Resolve an Entrez GDS UID to GEO metadata.\n",
    "    \"\"\"\n",
    "    handle = Entrez.esummary(db=\"gds\", id=uid)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "\n",
    "    doc = record[0]\n",
    "\n",
    "    summary = {\n",
    "        \"uid\": uid,\n",
    "        \"accession\": doc.get(\"Accession\"),\n",
    "        \"title\": doc.get(\"title\"),\n",
    "        \"gse\": doc.get(\"GSE\"),\n",
    "        \"type\": doc.get(\"gdsType\"),\n",
    "        \"platform\": doc.get(\"GPL\"),\n",
    "        \"n_samples\": doc.get(\"n_samples\")\n",
    "    }\n",
    "\n",
    "    return json.dumps(summary, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1743ae12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_call': {'name': 'geo_summary', 'arguments': {'uid': '200289404'}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"tool_call\": {\n",
    "    \"name\": \"geo_summary\",\n",
    "    \"arguments\": {\n",
    "      \"uid\": \"200289404\"\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c63ed09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prompt is what turns Qwen into an agent instead of a chatbot.\n",
    "AGENT_SYSTEM_PROMPT = \"\"\"\n",
    "You are a bioinformatics research agent.\n",
    "\n",
    "You have access to TWO tools:\n",
    "- geo_search(query: str) → returns Entrez GEO UIDs\n",
    "- geo_summary(uid: str) → returns metadata for a GEO UID\n",
    "\n",
    "Rules:\n",
    "- You may call ONLY ONE tool per response.\n",
    "- If you need to search GEO, output ONLY a JSON tool call.\n",
    "- Do NOT hallucinate GEO accessions.\n",
    "- GEO search results are Entrez UIDs, NOT GSE accessions.\n",
    "- Never add prefixes like GSE/GDS unless explicitly provided by a tool.\n",
    "- Always resolve UIDs using geo_summary before interpretation.\n",
    "- Do not mix explanations with tool calls.\n",
    "- If a field is not present in tool output, say \"unknown\".\n",
    "- Ask the user before downloading any dataset.\n",
    "\n",
    "After resolving a UID, determine:\n",
    "- Whether the dataset is single-cell RNA-seq\n",
    "- Whether processed files are available (h5ad, Seurat, RDS, loom)\n",
    "- Organism and biological context\n",
    "\n",
    "Tool call format (EXACT):\n",
    "\n",
    "{\n",
    "  \"tool_call\": {\n",
    "    \"name\": \"geo_search\",\n",
    "    \"arguments\": {\n",
    "      \"query\": \"...\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "or\n",
    "\n",
    "{\n",
    "  \"tool_call\": {\n",
    "    \"name\": \"geo_summary\",\n",
    "    \"arguments\": {\n",
    "      \"uid\": \"...\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74cb8e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/tools/miniconda3/envs/torch_gpu_dna/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/data/tools/miniconda3/envs/torch_gpu_dna/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "## Loading a Qwen model\n",
    "# conda activate torch_gpu_dna\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "## KimiK2 thinking cannot be downloaded so we start with Qwen. Also my GPU is Tesla T4 so I will stick to Qwen-7B.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1556c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is just generating the text\n",
    "def run_llm(messages, max_new_tokens=512):\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.2,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(\n",
    "        output_ids[0][inputs[\"input_ids\"].shape[-1]:],\n",
    "        skip_special_tokens=True\n",
    "    ).strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb7af2",
   "metadata": {},
   "source": [
    "#### Tool-call detector (the agent “router”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0690dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_tool_call(text: str):\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "        if \"tool_call\" in data:\n",
    "            return data[\"tool_call\"]\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b854fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def run_agent(prompt, max_steps=5):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": AGENT_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        # 1. Generate model output\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "        model_inputs = tokenizer(inputs, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                **model_inputs,\n",
    "                max_new_tokens=512,\n",
    "                do_sample=False,\n",
    "            )\n",
    "\n",
    "        response = tokenizer.decode(\n",
    "            output_ids[0][model_inputs[\"input_ids\"].shape[-1]:],\n",
    "            skip_special_tokens=True\n",
    "        ).strip()\n",
    "\n",
    "        print(f\"\\nLLM OUTPUT:\\n{response}\")\n",
    "\n",
    "        # 2. Try parsing tool call\n",
    "        try:\n",
    "            data = json.loads(response)\n",
    "            tool_call = data.get(\"tool_call\")\n",
    "        except json.JSONDecodeError:\n",
    "            # Normal text → done\n",
    "            return response\n",
    "\n",
    "        if tool_call:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            args = tool_call[\"arguments\"]\n",
    "\n",
    "            # 3. Execute tool\n",
    "            if tool_name == \"geo_search\":\n",
    "                result = geo_search(**args)\n",
    "            elif tool_name == \"geo_summary\":\n",
    "                result = geo_summary(**args)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "\n",
    "            print(f\"\\nTOOL RESULT:\\n{result}\")\n",
    "\n",
    "            # 4. Feed tool result back to model\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response\n",
    "            })\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": tool_name,\n",
    "                \"content\": result\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            return response\n",
    "\n",
    "    raise RuntimeError(\"Agent did not finish in time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b08d259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM OUTPUT:\n",
      "{\n",
      "  \"tool_call\": {\n",
      "    \"name\": \"geo_search\",\n",
      "    \"arguments\": {\n",
      "      \"query\": \"immune cell aging single-cell RNA-seq\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "TOOL RESULT:\n",
      "[\"200289404\", \"200164476\", \"200125300\"]\n",
      "\n",
      "LLM OUTPUT:\n",
      "{\n",
      "  \"tool_call\": {\n",
      "    \"name\": \"geo_summary\",\n",
      "    \"arguments\": {\n",
      "      \"uid\": \"200289404\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "TOOL RESULT:\n",
      "{\n",
      "  \"uid\": \"200289404\",\n",
      "  \"accession\": \"GSE289404\",\n",
      "  \"title\": \"Inflammatory Bowel Disease Leads to Long-Term Ovarian Dysfunction via Immune-Mediated Follicular Aging\",\n",
      "  \"gse\": \"289404\",\n",
      "  \"type\": \"Expression profiling by high throughput sequencing\",\n",
      "  \"platform\": \"34290\",\n",
      "  \"n_samples\": 14\n",
      "}\n",
      "\n",
      "LLM OUTPUT:\n",
      "The dataset with UID 200289404 is not a single-cell RNA-seq dataset. It is an expression profiling by high throughput sequencing dataset with accession GSE289404. The platform used is 34290, which corresponds to the Illumina HiSeq 2500 platform. No processed files are available for this dataset.\n",
      "\n",
      "Would you like to search for another dataset?\n",
      "\n",
      "FINAL OUTPUT:\n",
      " The dataset with UID 200289404 is not a single-cell RNA-seq dataset. It is an expression profiling by high throughput sequencing dataset with accession GSE289404. The platform used is 34290, which corresponds to the Illumina HiSeq 2500 platform. No processed files are available for this dataset.\n",
      "\n",
      "Would you like to search for another dataset?\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "Find single-cell RNA-seq datasets related to immune cell aging.\n",
    "Prefer processed data formats if possible.\n",
    "\"\"\"\n",
    "\n",
    "final_output = run_agent(query)\n",
    "print(\"\\nFINAL OUTPUT:\\n\", final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af647724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751c50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
