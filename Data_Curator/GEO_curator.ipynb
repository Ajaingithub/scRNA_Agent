{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55bd0215",
   "metadata": {},
   "source": [
    "# GEO Curator\n",
    "\n",
    "Making an agent that could find the single cell RNA dataset and find the h5ad, h5Seurat, csv files and downloaded if approved by the user\n",
    "\n",
    "Agent loop through:\n",
    "1. Uses Qwen locally\n",
    "2. Lets the model decide to call a tool\n",
    "3. Executes geo_search\n",
    "4. Feeds results back\n",
    "5. Optionally downloads a dataset\n",
    "\n",
    "User question → LLM thinks → decides: \"I need GEO\" → LLM outputs TOOL_CALL(JSON) → Python executes geo_search() → Tool result injected back into LLM → LLM continues reasoning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9ceef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a tool\n",
    "import json\n",
    "from Bio import Entrez\n",
    "\n",
    "Entrez.email = \"abhinavjj@gmail.com\"\n",
    "\n",
    "def geo_search(query: str, retmax: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Search GEO DataSets (GDS) using a query string.\n",
    "    Returns a JSON string of GEO IDs.\n",
    "    \"\"\"\n",
    "    handle = Entrez.esearch(\n",
    "        db=\"gds\",\n",
    "        term=query,\n",
    "        retmax=retmax\n",
    "    )\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return json.dumps(record[\"IdList\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8fe47",
   "metadata": {},
   "source": [
    "Since LLM is hard constraints we tell Qwen: If you want to call a tool, output EXACTLY this JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76399099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_call': {'name': 'geo_search', 'arguments': {'query': 'string'}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"tool_call\": {\n",
    "    \"name\": \"geo_search\",\n",
    "    \"arguments\": {\n",
    "      \"query\": \"string\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "# Other wise Normal text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "114911e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_ftp_links(soft_text):\n",
    "    ftp_links = re.findall(r'ftp://[^\\s]+', soft_text)\n",
    "    return list(set(ftp_links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f2c9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_summary(uid):\n",
    "    # Step 1: Summary\n",
    "    handle = Entrez.esummary(db=\"gds\", id=uid)\n",
    "    summary = Entrez.read(handle)\n",
    "    handle.close()\n",
    "\n",
    "    # Step 2: Full SOFT (text, not XML)\n",
    "    handle = Entrez.efetch(\n",
    "        db=\"gds\",\n",
    "        id=uid,\n",
    "        rettype=\"full\",\n",
    "        retmode=\"text\"\n",
    "    )\n",
    "    soft_text = handle.read()\n",
    "    handle.close()\n",
    "\n",
    "    ftp_links = extract_ftp_links(soft_text)\n",
    "\n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"ftp_links\": ftp_links\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "018baefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': [{'Item': [], 'Id': '200301650', 'Accession': 'GSE301650', 'GDS': '', 'title': 'Single-cell RNA-seq of isolated non-parenchymal cells from imiquimod-induced psoriasis mouse model.', 'summary': 'We applied 10x Genomics single-cell RNA sequencing to profile non-parenchymal liver cells (NPCs) in a psoriasis-like mouse model. The study focuses on immune and liver sinusoidal endothelial cell (LSEC) alterations along the skin–liver axis to elucidate mechanisms driving comorbid liver disease in psoriasis. Given that 30–50% of psoriasis patients develop liver involvement, this approach aims to identify maladaptive cellular crosstalk and potential therapeutic targets.', 'GPL': '24247', 'GSE': '301650', 'taxon': 'Mus musculus', 'entryType': 'GSE', 'gdsType': 'Expression profiling by high throughput sequencing', 'ptechType': '', 'valType': '', 'SSInfo': '', 'subsetInfo': '', 'PDAT': '2026/01/01', 'suppFile': 'MTX, TSV', 'Samples': [{'Accession': 'GSM9086914', 'Title': 'Liver NPCs, Imiquimod, biol rep 4'}, {'Accession': 'GSM9086911', 'Title': 'Liver NPCs, Imiquimod, biol rep 1'}, {'Accession': 'GSM9086917', 'Title': 'Liver NPCs, Vaseline, biol rep 3'}, {'Accession': 'GSM9086915', 'Title': 'Liver NPCs, Vaseline, biol rep 1'}, {'Accession': 'GSM9086912', 'Title': 'Liver NPCs, Imiquimod, biol rep 2'}, {'Accession': 'GSM9086918', 'Title': 'Liver NPCs, Vaseline, biol rep 4'}, {'Accession': 'GSM9086913', 'Title': 'Liver NPCs, Imiquimod, biol rep 3'}, {'Accession': 'GSM9086916', 'Title': 'Liver NPCs, Vaseline, biol rep 2'}], 'Relations': [], 'ExtRelations': [], 'n_samples': IntegerElement(8, attributes={}), 'SeriesTitle': '', 'PlatformTitle': '', 'PlatformTaxa': '', 'SamplesTaxa': '', 'PubMedIds': [], 'Projects': [], 'FTPLink': 'ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE301nnn/GSE301650/', 'GEO2R': 'no'}],\n",
       " 'ftp_links': ['ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE301nnn/GSE301650/']}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_summary(200301650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f18bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new GEO with extracting of the FTP link to be downloaded\n",
    "import json\n",
    "from Bio import Entrez\n",
    "import re\n",
    "\n",
    "Entrez.email = \"abhinavjj@gmail.com\"\n",
    "\n",
    "def geo_summary(uid: str) -> str:\n",
    "    Entrez.email = \"abhinavjj@gmail.com\"\n",
    "\n",
    "    # --- Step 1: Get GSE accession ---\n",
    "    handle = Entrez.esummary(db=\"gds\", id=uid)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "\n",
    "    doc = record[0]\n",
    "    gse = doc.get(\"Accession\")\n",
    "\n",
    "    summary = {\n",
    "        \"uid\": uid,\n",
    "        \"accession\": gse,\n",
    "        \"title\": doc.get(\"title\", \"unknown\"),\n",
    "        \"type\": doc.get(\"gdsType\", \"unknown\"),\n",
    "        \"platform\": doc.get(\"GPL\", \"unknown\"),\n",
    "        \"n_samples\": doc.get(\"n_samples\", \"unknown\"),\n",
    "        \"supplementary_files\": []\n",
    "    }\n",
    "\n",
    "    if not gse:\n",
    "        return json.dumps(summary, indent=2)\n",
    "\n",
    "    # --- Step 2: Fetch GEO XML summary ---\n",
    "    handle = Entrez.efetch(\n",
    "        db=\"gds\",\n",
    "        id=uid,\n",
    "        # rettype=\"summary\",\n",
    "        retmode=\"xml\"\n",
    "    )\n",
    "    # records = Entrez.read(handle)\n",
    "    soft_text = handle.read()\n",
    "    handle.close()\n",
    "\n",
    "    # --- Step 3: Extract FTP links safely ---\n",
    "    ftp_links = []\n",
    "\n",
    "    def walk(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for v in obj.values():\n",
    "                walk(v)\n",
    "        elif isinstance(obj, list):\n",
    "            for v in obj:\n",
    "                walk(v)\n",
    "        elif isinstance(obj, str) and obj.startswith(\"ftp://\"):\n",
    "            ftp_links.append(obj)\n",
    "\n",
    "    walk(records)\n",
    "\n",
    "    summary[\"supplementary_files\"] = sorted(set(ftp_links))\n",
    "\n",
    "    return json.dumps(summary, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "064ab0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def geo_download_from_ftp(ftp_url: str):\n",
    "    import requests, os\n",
    "\n",
    "    filename = os.path.basename(ftp_url)\n",
    "    r = requests.get(ftp_url, stream=True)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    with open(filename, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "\n",
    "    return f\"Downloaded {filename}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1743ae12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_call': {'name': 'geo_summary', 'arguments': {'uid': '200289404'}}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"tool_call\": {\n",
    "    \"name\": \"geo_summary\",\n",
    "    \"arguments\": {\n",
    "      \"uid\": \"200289404\"\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c63ed09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_SYSTEM_PROMPT = \"\"\"\n",
    "You are a bioinformatics research agent specializing in single-cell RNA-seq data curation.\n",
    "\n",
    "You have access to TWO tools:\n",
    "1. geo_search(query: str) → returns GEO Entrez UIDs\n",
    "2. geo_download_from_ftp(ftp_url: str) → downloads processed GSE* processed file\n",
    "\n",
    "Rules:\n",
    "- You may call ONLY ONE tool per response.\n",
    "- If you need to search GEO, output ONLY a JSON tool call.\n",
    "- Do NOT hallucinate GEO accessions.\n",
    "- GEO search results are Entrez UIDs, NOT GSE accessions.\n",
    "- UID resolution (UID → GSE → metadata) will be provided to you as tool output.\n",
    "- You may ONLY use GSE accessions explicitly provided in tool results.\n",
    "- Do not mix explanations with tool calls.\n",
    "- If a field is missing, say \"unknown\".\n",
    "- Ask the user for confirmation BEFORE downloading any dataset.\n",
    "- NEVER construct or guess GEO FTP URLs.\n",
    "- FTP links MUST be extracted verbatim from supplementary file fields in geo_summary.\n",
    "- If no supplementary FTP link exists, report \"unknown\".\n",
    "- Download ONLY one ftp link from supplementary files.\n",
    "\n",
    "After UID resolution, analyze each dataset and determine:\n",
    "- Is this single-cell RNA-seq?\n",
    "- What organism and immune context?\n",
    "- Are RAW or processed files available?\n",
    "- Does it match the user’s biological question?\n",
    "\n",
    "Tool call formats (EXACT):\n",
    "\n",
    "{\n",
    "  \"tool_call\": {\n",
    "    \"name\": \"geo_search\",\n",
    "    \"arguments\": {\n",
    "      \"query\": \"...\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "{\n",
    "  \"tool_call\": {\n",
    "    \"name\": \"geo_download_from_ftp\",\n",
    "    \"arguments\": {\n",
    "      \"ftp_url\": \"...\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74cb8e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/tools/miniconda3/envs/torch_gpu_dna/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/data/tools/miniconda3/envs/torch_gpu_dna/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.38s/it]\n"
     ]
    }
   ],
   "source": [
    "## Loading a Qwen model\n",
    "# conda activate torch_gpu_dna\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "## KimiK2 thinking cannot be downloaded so we start with Qwen. Also my GPU is Tesla T4 so I will stick to Qwen-7B.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1556c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is just generating the like provide you the plan as you instructed the agent\n",
    "def run_llm(messages, max_new_tokens=512):\n",
    "    # This line converts structured chat messages into a single text prompt in the \n",
    "    # exact format the model was trained on.\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    # It tokenizes based on the model tokenization was done.\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad(): # Since inference not training\n",
    "        output_ids = model.generate( # autoregressive text generation\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.2, # randomness or creativity is low\n",
    "            do_sample=False # does not matter about the randomness\n",
    "        )\n",
    "    return tokenizer.decode(\n",
    "        output_ids[0][inputs[\"input_ids\"].shape[-1]:],\n",
    "        skip_special_tokens=True\n",
    "    ).strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb7af2",
   "metadata": {},
   "source": [
    "#### Tool-call detector (the agent “router”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0690dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_tool_call(text: str):\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "        if \"tool_call\" in data:\n",
    "            return data[\"tool_call\"]\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b854fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def run_agent(prompt, max_steps=5):\n",
    "    # This message is just the initialization where Agent System Prompt tells the agent what to do and user provided the input\n",
    "    # Then in the message it keep on getting appended more messages, tools etc.\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": AGENT_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    for step in range(max_steps):\n",
    "        print(f'step:{step}')\n",
    "        # This line converts structured chat messages into a single text prompt in the \n",
    "        # exact format the model was trained on.\n",
    "        # every time model see the full history what has happened. \n",
    "        # This converts all previous messages into a single prompt\n",
    "        # The model sees everything:\n",
    "        # system rules\n",
    "        # user query\n",
    "        # previous tool calls\\\n",
    "        # previous tool results\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        # It tokenizes based on the model tokenization was done.\n",
    "        model_inputs = tokenizer(inputs, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad(): # Since inference not training\n",
    "            output_ids = model.generate( # autoregressive text generation\n",
    "                **model_inputs,\n",
    "                max_new_tokens=512,\n",
    "                do_sample=False,\n",
    "            )\n",
    "        response = tokenizer.decode(\n",
    "            output_ids[0][model_inputs[\"input_ids\"].shape[-1]:],\n",
    "            skip_special_tokens=True\n",
    "        ).strip()\n",
    "        print(f\"\\nLLM OUTPUT:\\n{response}\") ## This returns only the JSON since it is instructed in the Agent system prompt when geo_search is called\n",
    "        # while when geo_summary is called it will result the output in the language\n",
    "        # 2. Try parsing tool call\n",
    "        try:\n",
    "            data = json.loads(response) \n",
    "            tool_call = data.get(\"tool_call\") # if there is a tool call it is true\n",
    "        except json.JSONDecodeError:\n",
    "            # Normal text → done\n",
    "            return response\n",
    "        if tool_call:\n",
    "            tool_name = tool_call[\"name\"] # tool name whether geo_search or geo_summary\n",
    "            args = tool_call[\"arguments\"]\n",
    "            # 3. Execute tool\n",
    "            # if tool_name == \"geo_search\": # this is taking only one UID\n",
    "            #     result = geo_search(**args)\n",
    "            if tool_name == \"geo_search\": # this can take multiple UID and feed to geo_summary\n",
    "                uids = json.loads(geo_search(**args))\n",
    "                summaries = []\n",
    "                for uid in uids:\n",
    "                    summaries.append(json.loads(geo_summary(uid=uid)))\n",
    "                result = json.dumps(summaries, indent=2)\n",
    "                # print(f'geo_search result: {result}')\n",
    "            # elif tool_name == \"geo_summary\":\n",
    "            #     result = geo_summary(**args)\n",
    "            elif tool_name == \"geo_download_from_ftp\":\n",
    "                result = geo_download_from_ftp(**args)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "            print(f\"\\nTOOL RESULT:\\n{result}\")\n",
    "            # 4. Feed tool result back to model\n",
    "            # After every step, you append new entries so the model can reason based on what already happened.\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response\n",
    "            })\n",
    "            # Models trained for tool calling (Qwen, Llama, GPT-style) expect:\n",
    "            # | Role        | Meaning                           |\n",
    "            # | ----------- | --------------------------------- |\n",
    "            # | `system`    | Rules and behavior                |\n",
    "            # | `user`      | Human request                     |\n",
    "            # | `assistant` | Model’s reasoning / tool decision |\n",
    "            # | `tool`      | External factual input            |\n",
    "            # when role: tool it knows: “This came from the real world, not my imagination.”\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": tool_name,\n",
    "                \"content\": result\n",
    "            })\n",
    "            # So you need to append both assistant and the tool\n",
    "            # Assistant\t“I decided to call a tool”\n",
    "            # Tool\t“Here is the result of that tool”\n",
    "        else:\n",
    "            return response\n",
    "    raise RuntimeError(\"Agent did not finish in time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b08d259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0\n",
      "\n",
      "LLM OUTPUT:\n",
      "{\n",
      "  \"tool_call\": {\n",
      "    \"name\": \"geo_search\",\n",
      "    \"arguments\": {\n",
      "      \"query\": \"immune cell aging single-cell RNA-seq processed\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "ename": "StreamModeError",
     "evalue": "the XML file must be opened in binary mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStreamModeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mFind single-cell RNA-seq datasets related to immune cell aging.\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mPrefer processed data formats if possible.\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[43mrun_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFINAL OUTPUT:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, final_output)\n",
      "Cell \u001b[0;32mIn[70], line 57\u001b[0m, in \u001b[0;36mrun_agent\u001b[0;34m(prompt, max_steps)\u001b[0m\n\u001b[1;32m     55\u001b[0m     summaries \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m uid \u001b[38;5;129;01min\u001b[39;00m uids:\n\u001b[0;32m---> 57\u001b[0m         summaries\u001b[38;5;241m.\u001b[39mappend(json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mgeo_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43muid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muid\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     58\u001b[0m     result \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(summaries, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# print(f'geo_search result: {result}')\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# elif tool_name == \"geo_summary\":\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m#     result = geo_summary(**args)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[69], line 39\u001b[0m, in \u001b[0;36mgeo_summary\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# --- Step 2: Fetch GEO XML summary ---\u001b[39;00m\n\u001b[1;32m     33\u001b[0m handle \u001b[38;5;241m=\u001b[39m Entrez\u001b[38;5;241m.\u001b[39mefetch(\n\u001b[1;32m     34\u001b[0m     db\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgds\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39muid,\n\u001b[1;32m     36\u001b[0m     rettype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# retmode=\"xml\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 39\u001b[0m records \u001b[38;5;241m=\u001b[39m \u001b[43mEntrez\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m handle\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# --- Step 3: Extract FTP links safely ---\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/data/tools/miniconda3/envs/torch_gpu_dna/lib/python3.10/site-packages/Bio/Entrez/__init__.py:529\u001b[0m, in \u001b[0;36mread\u001b[0;34m(source, validate, escape, ignore_errors)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataHandler\n\u001b[1;32m    528\u001b[0m handler \u001b[38;5;241m=\u001b[39m DataHandler(validate, escape, ignore_errors)\n\u001b[0;32m--> 529\u001b[0m record \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m record\n",
      "File \u001b[0;32m/mnt/data/tools/miniconda3/envs/torch_gpu_dna/lib/python3.10/site-packages/Bio/Entrez/Parser.py:398\u001b[0m, in \u001b[0;36mDataHandler.read\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# not a path, assume we received a stream\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 398\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m StreamModeError(\n\u001b[1;32m    399\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe XML file must be opened in binary mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    400\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     stream \u001b[38;5;241m=\u001b[39m source\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mStreamModeError\u001b[0m: the XML file must be opened in binary mode."
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "Find single-cell RNA-seq datasets related to immune cell aging.\n",
    "Prefer processed data formats if possible.\n",
    "\"\"\"\n",
    "\n",
    "final_output = run_agent(query)\n",
    "print(\"\\nFINAL OUTPUT:\\n\", final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af647724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0\n",
      "\n",
      "LLM OUTPUT:\n",
      "{\n",
      "  \"tool_call\": {\n",
      "    \"name\": \"geo_search\",\n",
      "    \"arguments\": {\n",
      "      \"query\": \"single cell RNA-seq immune\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "geo_search result: [\n",
      "  {\n",
      "    \"uid\": \"200301650\",\n",
      "    \"accession\": \"GSE301650\",\n",
      "    \"title\": \"Single-cell RNA-seq of isolated non-parenchymal cells from imiquimod-induced psoriasis mouse model.\",\n",
      "    \"gse\": \"301650\",\n",
      "    \"type\": \"Expression profiling by high throughput sequencing\",\n",
      "    \"platform\": \"24247\",\n",
      "    \"n_samples\": 8\n",
      "  },\n",
      "  {\n",
      "    \"uid\": \"200301873\",\n",
      "    \"accession\": \"GSE301873\",\n",
      "    \"title\": \"TGF-\\u03b2RII/IL-15 Immunotherapeutic complex targets exhausted CD8+ T cell subsets in lymph nodes and tumors\",\n",
      "    \"gse\": \"301873\",\n",
      "    \"type\": \"Expression profiling by high throughput sequencing\",\n",
      "    \"platform\": \"21103\",\n",
      "    \"n_samples\": 4\n",
      "  },\n",
      "  {\n",
      "    \"uid\": \"200293951\",\n",
      "    \"accession\": \"GSE293951\",\n",
      "    \"title\": \"Single cell RNA-seq of myeloid immune cells in melanoma-draining lymph nodes\",\n",
      "    \"gse\": \"293951\",\n",
      "    \"type\": \"Expression profiling by high throughput sequencing\",\n",
      "    \"platform\": \"24247\",\n",
      "    \"n_samples\": 3\n",
      "  },\n",
      "  {\n",
      "    \"uid\": \"200275096\",\n",
      "    \"accession\": \"GSE275096\",\n",
      "    \"title\": \"DNA-damaging Chemotherapy altered the Cardiac Pathogenesis by reshaping the Composition and Functionality of Cardiac Resident Macrophages (bulk RNA-Seq).\",\n",
      "    \"gse\": \"275096\",\n",
      "    \"type\": \"Expression profiling by high throughput sequencing\",\n",
      "    \"platform\": \"24247\",\n",
      "    \"n_samples\": 35\n",
      "  },\n",
      "  {\n",
      "    \"uid\": \"200275095\",\n",
      "    \"accession\": \"GSE275095\",\n",
      "    \"title\": \"DNA-damaging Chemotherapy altered the Cardiac Pathogenesis by reshaping the Composition and Functionality of Cardiac Resident Macrophages (scRNA-Seq).\",\n",
      "    \"gse\": \"275095\",\n",
      "    \"type\": \"Expression profiling by high throughput sequencing\",\n",
      "    \"platform\": \"24247\",\n",
      "    \"n_samples\": 4\n",
      "  }\n",
      "]\n",
      "\n",
      "TOOL RESULT:\n",
      "[\n",
      "  {\n",
      "    \"uid\": \"200301650\",\n",
      "    \"accession\": \"GSE301650\",\n",
      "    \"title\": \"Single-cell RNA-seq of isolated non-parenchymal cells from imiquimod-induced psoriasis mouse model.\",\n",
      "    \"gse\": \"301650\",\n",
      "    \"type\": \"Expression profiling by high throughput sequencing\",\n",
      "    \"platform\": \"24247\",\n",
      "    \"n_samples\": 8\n",
      "  },\n",
      "  {\n",
      "    \"uid\": \"200301873\",\n",
      "    \"accession\": \"GSE301873\",\n",
      "    \"title\": \"TGF-\\u03b2RII/IL-15 Immunotherapeutic complex targets exhausted CD8+ T cell subsets in lymph nodes and tumors\",\n",
      "    \"gse\": \"301873\",\n",
      "    \"type\": \"Expression profiling by high throughput sequencing\",\n",
      "    \"platform\": \"21103\",\n",
      "    \"n_samples\": 4\n",
      "  },\n",
      "  {\n",
      "    \"uid\": \"200293951\",\n",
      "    \"accession\": \"GSE293951\",\n",
      "    \"title\": \"Single cell RNA-seq of myeloid immune cells in melanoma-draining lymph nodes\",\n",
      "    \"gse\": \"293951\",\n",
      "    \"type\": \"Expression profiling by high throughput sequencing\",\n",
      "    \"platform\": \"24247\",\n",
      "    \"n_samples\": 3\n",
      "  },\n",
      "  {\n",
      "    \"uid\": \"200275096\",\n",
      "    \"accession\": \"GSE275096\",\n",
      "    \"title\": \"DNA-damaging Chemotherapy altered the Cardiac Pathogenesis by reshaping the Composition and Functionality of Cardiac Resident Macrophages (bulk RNA-Seq).\",\n",
      "    \"gse\": \"275096\",\n",
      "    \"type\": \"Expression profiling by high throughput sequencing\",\n",
      "    \"platform\": \"24247\",\n",
      "    \"n_samples\": 35\n",
      "  },\n",
      "  {\n",
      "    \"uid\": \"200275095\",\n",
      "    \"accession\": \"GSE275095\",\n",
      "    \"title\": \"DNA-damaging Chemotherapy altered the Cardiac Pathogenesis by reshaping the Composition and Functionality of Cardiac Resident Macrophages (scRNA-Seq).\",\n",
      "    \"gse\": \"275095\",\n",
      "    \"type\": \"Expression profiling by high throughput sequencing\",\n",
      "    \"platform\": \"24247\",\n",
      "    \"n_samples\": 4\n",
      "  }\n",
      "]\n",
      "step:1\n",
      "\n",
      "LLM OUTPUT:\n",
      "Based on the provided GEO search results, here are the analyzed datasets:\n",
      "\n",
      "1. **GSE301650**\n",
      "   - **Type**: Single-cell RNA-seq\n",
      "   - **Processed Files Available**: No specific file types mentioned, but it's likely that raw data is available.\n",
      "   - **Organism**: Mouse\n",
      "   - **Biological Context**: Non-parenchymal cells from imiquimod-induced psoriasis mouse model.\n",
      "   - **Matches User’s Question**: Yes, this dataset involves immune cells and is relevant to psoriasis, which is an immune-related condition.\n",
      "\n",
      "2. **GSE301873**\n",
      "   - **Type**: Single-cell RNA-seq (not explicitly stated, but similar to GSE301650)\n",
      "   - **Processed Files Available**: No specific file types mentioned, but it's likely that raw data is available.\n",
      "   - **Organism**: Mouse\n",
      "   - **Biological Context**: TGF-βRII/IL-15 immunotherapy and its effect on CD8+ T cells.\n",
      "   - **Matches User’s Question**: Yes, this dataset involves immune cells and is relevant to T cell function and immunotherapy.\n",
      "\n",
      "3. **GSE293951**\n",
      "   - **Type**: Single-cell RNA-seq\n",
      "   - **Processed Files Available**: No specific file types mentioned, but it's likely that raw data is available.\n",
      "   - **Organism**: Mouse\n",
      "   - **Biological Context**: Myeloid immune cells in melanoma-draining lymph nodes.\n",
      "   - **Matches User’s Question**: Yes, this dataset involves immune cells and is relevant to melanoma and immune responses.\n",
      "\n",
      "4. **GSE275096**\n",
      "   - **Type**: Bulk RNA-seq\n",
      "   - **Processed Files Available**: No specific file types mentioned, but it's likely that raw data is available.\n",
      "   - **Organism**: Mouse\n",
      "   - **Biological Context**: Cardiac macrophages after DNA-damaging chemotherapy.\n",
      "   - **Matches User’s Question**: No, this dataset does not involve single-cell RNA-seq and focuses on bulk RNA-seq of cardiac macrophages.\n",
      "\n",
      "5. **GSE275095**\n",
      "   - **Type**: Single-cell RNA-seq\n",
      "   - **Processed Files Available**: No specific file types mentioned, but it's likely that raw data is available.\n",
      "   - **Organism**: Mouse\n",
      "   - **Biological Context\n",
      "\n",
      "FINAL OUTPUT:\n",
      " Based on the provided GEO search results, here are the analyzed datasets:\n",
      "\n",
      "1. **GSE301650**\n",
      "   - **Type**: Single-cell RNA-seq\n",
      "   - **Processed Files Available**: No specific file types mentioned, but it's likely that raw data is available.\n",
      "   - **Organism**: Mouse\n",
      "   - **Biological Context**: Non-parenchymal cells from imiquimod-induced psoriasis mouse model.\n",
      "   - **Matches User’s Question**: Yes, this dataset involves immune cells and is relevant to psoriasis, which is an immune-related condition.\n",
      "\n",
      "2. **GSE301873**\n",
      "   - **Type**: Single-cell RNA-seq (not explicitly stated, but similar to GSE301650)\n",
      "   - **Processed Files Available**: No specific file types mentioned, but it's likely that raw data is available.\n",
      "   - **Organism**: Mouse\n",
      "   - **Biological Context**: TGF-βRII/IL-15 immunotherapy and its effect on CD8+ T cells.\n",
      "   - **Matches User’s Question**: Yes, this dataset involves immune cells and is relevant to T cell function and immunotherapy.\n",
      "\n",
      "3. **GSE293951**\n",
      "   - **Type**: Single-cell RNA-seq\n",
      "   - **Processed Files Available**: No specific file types mentioned, but it's likely that raw data is available.\n",
      "   - **Organism**: Mouse\n",
      "   - **Biological Context**: Myeloid immune cells in melanoma-draining lymph nodes.\n",
      "   - **Matches User’s Question**: Yes, this dataset involves immune cells and is relevant to melanoma and immune responses.\n",
      "\n",
      "4. **GSE275096**\n",
      "   - **Type**: Bulk RNA-seq\n",
      "   - **Processed Files Available**: No specific file types mentioned, but it's likely that raw data is available.\n",
      "   - **Organism**: Mouse\n",
      "   - **Biological Context**: Cardiac macrophages after DNA-damaging chemotherapy.\n",
      "   - **Matches User’s Question**: No, this dataset does not involve single-cell RNA-seq and focuses on bulk RNA-seq of cardiac macrophages.\n",
      "\n",
      "5. **GSE275095**\n",
      "   - **Type**: Single-cell RNA-seq\n",
      "   - **Processed Files Available**: No specific file types mentioned, but it's likely that raw data is available.\n",
      "   - **Organism**: Mouse\n",
      "   - **Biological Context\n"
     ]
    }
   ],
   "source": [
    "# now searching in the GSE than GDS\n",
    "query = (\n",
    "    \"single cell[All Fields] AND RNA-seq[All Fields] AND immune[All Fields]\"\n",
    ")\n",
    "\n",
    "final_output = run_agent(query)\n",
    "print(\"\\nFINAL OUTPUT:\\n\", final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751c50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5fc48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
